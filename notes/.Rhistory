getwd()
library(data.table)
library(glmnet)
library(ggplot2)
library(mlbench)
library(caret)
library(splines)
library(ggeffects)
# load data
trumpbernie <- fread(file = "~/Documents/ML/Labs/Lab1/trumpbernie.csv")
# inspect
trumpbernie[1:10,1:10]
dim(trumpbernie)
mymodel <- glm(trump_tweet ~ ., data = trumpbernie, family="binomial")
# sum(!is.na(test))
coef(mymodel)[(1001:1050)]
# Extract predictions on training data & observed values
comparison_df <- data.frame(train_predictions=mymodel$fitted.values,
observed=mymodel$y)
# Apply prediction threshold
comparison_df$train_predictions<-ifelse(comparison_df$train_predictions>=0.5,
yes = 1,
no = 0)
# Compute accuracy (scale: 0-1, 0=0%, 1=100%)
nrow(comparison_df[comparison_df$train_predictions==comparison_df$observed,]) /
nrow(comparison_df)
# format the outcome variable as a factor variable
trumpbernie$trump_tweet <- factor(trumpbernie$trump_tweet, levels = c(0,1))
# Use package "caret" to do k-fold cross-validation
tc <- caret::trainControl(method = 'cv', number = 3)
set.seed(12345) # Set to ensure that folds are the same across models
linear_model <- caret::train(trump_tweet ~ .,
data = trumpbernie,
method = "glm",
trControl = tc,
family = "binomial")
#| warning: false
#| message: false
library(data.table)
library(glmnet)
library(ggplot2)
library(mlbench)
library(caret)
library(splines)
library(ggeffects)
# load data
trumpbernie <- fread(file = "~/Documents/ML/Labs/Lab1/trumpbernie.csv")
# inspect
# trumpbernie[1:10,1:10]
dim(trumpbernie)
sum(!is.na(test))
test <- coef(mymodel)
sum(!is.na(test))
coefs_mymodel <- coef(mymodel)
sum(!is.na(test))
coefs_mymodel <- coef(mymodel)
sum(!is.na(coefs_mymodel))
coef(mymodel)[(1001:1050)]
sum(!is.na(coef(mymodel)))
coef(mymodel)[(1001:1050)]
# Extract predictions on training data & observed values
comparison_df <- data.frame(train_predictions=mymodel$fitted.values,
observed=mymodel$y)
# Apply prediction threshold
comparison_df$train_predictions<-ifelse(comparison_df$train_predictions>=0.5,
yes = 1,
no = 0)
# Compute accuracy (scale: 0-1, 0=0%, 1=100%)
nrow(comparison_df[comparison_df$train_predictions==comparison_df$observed,]) /
nrow(comparison_df)
# Compute accuracy (scale: 0-1, 0=0%, 1=100%)
nrow(comparison_df[comparison_df$train_predictions==comparison_df$observed,]) /
nrow(comparison_df)
# format the outcome variable as a factor variable
trumpbernie$trump_tweet <- factor(trumpbernie$trump_tweet, levels = c(0,1))
# Use package "caret" to do k-fold cross-validation
tc <- caret::trainControl(method = 'cv', number = 3)
set.seed(12345) # Set to ensure that folds are the same across models
linear_model <- caret::train(trump_tweet ~ .,
data = trumpbernie,
method = "glm",
trControl = tc,
family = "binomial")
# format the outcome variable as a factor variable
trumpbernie$trump_tweet <- factor(trumpbernie$trump_tweet, levels = c(0,1))
# Use package "caret" to do k-fold cross-validation
tc <- caret::trainControl(method = 'cv', number = 3)
set.seed(12345) # Set to ensure that folds are the same across models
linear_model <- caret::train(trump_tweet ~ .,
data = trumpbernie,
method = "glm",
trControl = tc,
family = "binomial")
linear_model$results
linear_model$results$Accuracy
pred_class <- predict(linear_model, newdata = trumpbernie)
pred_class <- predict(linear_model, newdata = trumpbernie)
train_acc <- mean(pred_class == trumpbernie$trump_tweet)
train_acc <- mean(pred_class == trumpbernie$trump_tweet)
train_acc
1 - train_acc
X <- trumpbernie[,-c('trump_tweet'),with=F] # Exclude response and id columns.
X <- as.matrix(X) # Make input data into a matrix
cvglmnet <- cv.glmnet(x = X,
y = trumpbernie$trump_tweet,
nfolds = 5,
standardize = TRUE,
family='binomial',
alpha=0,
type.measure = 'class')
cvglmnet <- cv.glmnet(x = X,
y = trumpbernie$trump_tweet,
nfolds = 5,
standardize = TRUE,
family='binomial',
alpha=0,
type.measure = 'class')
cvglmnet
cvglmnet$lambda.min
cvglmnet
cvglmnet$cvm
cvglmnet$index
cvglmnet$glmnet.fit
cvglmnet$cvm
cvglmnet
cvglmnet$cvm
cvglmnet$cvm |> min()
cvglmnet
cvglmnet$cvm |> min()
cvglmnet
cvglmnet$lambda.min
cvglmnet$cvm[which.min(abs(cvglmnet$lambda - lambda_target))]
cvglmnet$cvm[which.min(abs(cvglmnet$lambda - 0.01))]
cvglmnet$cvm[which.min(abs(cvglmnet$lambda - 0.11))]
cvglmnet$cvm[which.min(abs(cvglmnet$lambda - 0.1))]
which.min(abs(cvglmnet$lambda - 0.1))
which.min(abs(cvglmnet$lambda - 0.01))
cvglmnet
cvglmnet$index
cvglmnet$cve[cvglmnet$index, fold]
cvglmnet$cve[cvglmnet$index, 1]
cvglmnet$cve[cvglmnet$index, 3]
cvglmnet$cve[cvglmnet$index,]
cvglmnet$cve[cvglmnet$index]
cvglmnet$cvm[cvglmnet$index]
cvglmnet$index
cvglmnet$index$min
cvglmnet$index[min,]
cvglmnet$index |> class()
cvglmnet$index[[1]]
cvglmnet$index
cvglmnet$cvm[cvglmnet$index[[1]]]
cvglmnet$cvm[cvglmnet$index[[2]]]
cvglmnet$cve[cvglmnet$index]
cvglmnet$cvm[cvglmnet$index[[1]]]
cvglmnet$cvm[cvglmnet$index[[2]]]
cvglmnet$index
cvglmnet
cvglmnet$cvm[cvglmnet$index[[1]]]
1 - cvglmnet$cvm[cvglmnet$index[[1]]]
1 - cvglmnet$cvm[cvglmnet$index[[1]]]
1 - cvglmnet$cvm[cvglmnet$index[[1]]]
linear_model$results$Accuracy
plot(cvglmnet, sign.lambda = 1)
title("Cross-validation error for logistic regression (Ridge, 5-fold CV)")
plot(cvglmnet, sign.lambda = 1)
title("Cross-validation error for logistic regression (Ridge, 5-fold CV)")
plot(cvglmnet, sign.lambda = 1)
best_coefs <- coef(cvglmnet, s = "lambda.min")
best_coefs_dt <- data.table(word=rownames(best_coefs),
coef=best_coefs[,1])
best_coefs_dt[order(coef,decreasing = T)]
sna_data <- fread("~/Documents/ML/Labs/Lab1/Kaggle_Social_Network_Ads.csv")
sna_data$Purchased <- factor(sna_data$Purchased, levels = c(0,1))
# Use package "caret" to do k-fold cross-validation
tc <- caret::trainControl(method = 'cv', number = 5)
set.seed(12345) # Set to ensure that folds are the same across models
nonlinear_model <- caret::train(Purchased ~ .,
data = sna_data,
method = "glm",
trControl = tc,
family = "binomial")
nonlinear_model$results
