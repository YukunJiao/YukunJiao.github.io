[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "Jurassic World and Marx\n\n\n\nmovie\n\n\n\n\n\n\n\n\n\nAug 14, 2025\n\n\nYukun Jiao\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/ML.html#chapter-1",
    "href": "notes/ML.html#chapter-1",
    "title": "Machine Learning",
    "section": "Chapter 1",
    "text": "Chapter 1\nStatistical learning: a vast set of tools for understanding data. These tools can be classified as supervised or unsupervised.\nRegression: predicting a continuous or quantitative output value.\nClassification: predicting a categorical or qualitative output.\nClustering: grouping individuals according to their observed characteristics.\n\nNotation\n\nn — the number of distinct data points or observations\np — the number of variables that are available for use in making predictions\n\\(x_{ij}\\) — the value of the \\(j\\)th variable for the \\(i\\)th observation, where \\(i = 1, 2, \\dots, n\\) and \\(j = 1, 2, \\dots, p\\).\n\\(i\\) — observation index\n\\(j\\) — variable index\n\\(\\mathbf{X}\\) — an \\(n \\times p\\) matrix whose \\((i,j)\\)th element is \\(x_{ij}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs an example, consider\n\\[\nA = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}, \\quad\nB = \\begin{pmatrix} 5 & 6 \\\\ 7 & 8 \\end{pmatrix}.\n\\] Then\n\\[\nAB =\n\\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}\n\\begin{pmatrix} 5 & 6 \\\\ 7 & 8 \\end{pmatrix}\n=\n\\begin{pmatrix}\n1 \\times 5 + 2 \\times 7 & 1 \\times 6 + 2 \\times 8 \\\\\n3 \\times 5 + 4 \\times 7 & 3 \\times 6 + 4 \\times 8\n\\end{pmatrix}\n=\n\\begin{pmatrix} 19 & 22 \\\\ 43 & 50 \\end{pmatrix}\n\\]"
  },
  {
    "objectID": "notes/ML.html#chapter-2",
    "href": "notes/ML.html#chapter-2",
    "title": "Machine Learning",
    "section": "Chapter 2",
    "text": "Chapter 2\n\\(X\\) — input variables, predictors, independent variables, features, or just variables\n\\(Y\\) — response, dependent variable\n\\(Y = f(X) + \\epsilon\\), where \\(f\\) is some fixed but unknown function of \\(X\\), and \\(\\epsilon\\) is a random error term, which is independent of \\(X\\) and has mean zero (f represents the systematic information that \\(X\\) provides about \\(Y\\).).\nstatistical learning — a set of approaches for estimating \\(f\\)\n\n2.1.1 Why Estimate \\(f\\)?\n\nPrediction\n\\[\\hat{Y} = \\hat{f}(X)\\]\n\\(\\hat{f}\\) — our estimate for \\(f\\)\n\\(\\hat{Y}\\) — the resulting prediction for \\(Y\\)\nThe accuracy of \\(\\hat{Y}\\) as a prediction of \\(Y\\) depends on two quantities, reducible error and irreducible error.\nreducible error — We can potentially improve the accuracy of \\(\\hat{f}\\) by using the most appropriate statistical learning technique to estimate \\(f\\).\nirreducible error — introduced by \\(\\epsilon\\) (\\(\\hat{Y} = f(X)\\), \\(Y = f(X) + \\epsilon\\)); this error is lager than zero, because of unmeasured variables and unmeasurable variation in \\(\\epsilon\\).\nWe have\n\\[\n\\begin{aligned}\n\\mathrm{Var}(X)\n&= E\\big[(X - E[X])^2\\big] \\\\\n%&= E\\big[X^2 - 2X E[X] + (E[X])^2\\big] \\\\\n%&= E[X^2] - 2E[X] E[X] + (E[X])^2 \\\\\n&= E[X^2] - (E[X])^2\n\\end{aligned}\n\\]\nThus\n\\[\n\\begin{aligned}\n\\mathrm{Var}(\\epsilon)\n&= E[\\epsilon^2] - 0^2 \\\\\n&= E[\\epsilon^2]\n\\end{aligned}\n\\]\nThen\n\\[\n\\begin{aligned}\nE(Y - \\hat{Y})^2\n&= E\\big[ f(X) + \\epsilon - \\hat{f}(X) \\big]^2 \\\\\n&= E\\big[ (f(X) - \\hat{f}(X)) + \\epsilon \\big]^2 \\\\\n&= E\\big[ (f(X) - \\hat{f}(X))^2 + 2(f(X) - \\hat{f}(X))\\epsilon + \\epsilon^2 \\big] \\\\\n&= (f(X) - \\hat{f}(X))^2 + E(\\epsilon^2)\\\\\n&= (f(X) - \\hat{f}(X))^2 + \\mathrm{Var}(\\epsilon)\n\\end{aligned}\n\\]\nThat is\n\\[\nE(Y - \\hat{Y})^2\n= \\underbrace{(f(X) - \\hat{f}(X))^2}_{\\mathrm{Reducible}}\n    + \\underbrace{\\mathrm{Var}(\\epsilon)}_{\\mathrm{Irreducible}}\n\\]\n\n\nInference\nWe are often interested in understanding the association between \\(Y\\) and \\(X\\).\nNow \\(\\hat{f}\\) cannot be treated as a black box, because we need to know its exact form. In this setting, one may be interested in answering the following questions:\n\nWhich predictors are associated with the response?\nWhat is the relationship between the response and each predictor?\nCan the relationship between \\(Y\\) and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?\n\nFor example,\n\nWhich media are associated with sales?\nWhich media generate the biggest boost in sales?\nHow large of an increase in sales is associated with a given increase in TV advertising?\n\nAn example of modeling for inference — to what extent is the product’s price associated with sales?\nIn a real estate setting,\n\nHow much extra will a house be worth if it has a view of the river? (inference)\nIs this house under- or over-valued? (prediction)\n\nIn other words (ChatGPT),\n\nbetter understanding the relationship between the response and the predictors -&gt; Inference;\naccurately predicting the response for future observations -&gt; Prediction.\n\n\n\n\n2.1.2 How do we estimate \\(f\\)?\n\nParametric Methods\n\nWe make an assumption about the functional form, or shape, of \\(f\\). A very simple assumption is that \\(f\\) is linear in \\(X\\) (linear model):\n\n\\[\nf(X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p\n\\]\n\nAfter a model has been selected, we need a procedure that uses the training data to fit or train the model. We need to estimate the parameters \\(\\beta_0, \\beta_1, \\dots, \\beta_p\\)\n\nThat is\n\\[\nY \\approx \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p\n\\]\nThe most common approach to fitting the model is referred to as ordinary least squares (OLS).\n\n\nNon-Parametric Methods\nNon-parametric methods do not make explicit assumptions about the functional form of \\(f\\). Instead they seek an estimate of \\(f\\).\nSince they do not reduce the problem of estimating \\(f\\) to a small number of parameters, a very large number of observations (far more than is typically needed for a parametric approach) is required in order to obtain an accurate estimate for \\(f\\).\n\nthin-plate spline\n\nMore details in Chapter 7\n\n\n\n2.1.3 The Trade-Off Between Prediction Accuracy and Model Interpretability\nOne question: Why would we ever choose to use a more restrictive method instead of a very flexible approach?\nAnswer: We might choose a more restrictive method because it is easier to interpret. When our goal is inference, understanding the relationship between each predictor and the response is important, and very flexible methods can produce estimates that are too complex to interpret.\nSurprisingly, this is not always the case! We will often obtain more accurate predictions using a less flexible method. (due to overfitting in highly flexbile methods)\n\n\n2.1.5 Regression Versus Classification Problems\nChoice of statistical learning method mainly depends on the type of response:\n\nQuantitative response → linear regression\nQualitative response → logistic regression\n\nPredictor type (quantitative or qualitative) is generally less important, as long as any qualitative predictors are properly coded before analysis.\n\n\n2.2.1 Measuring the Quality of Fit\nWe need to quantify the extent to which the predicted response value for a given observation is close to the true response value for that observation. In the regression setting, the most commonly-used measure is the mean squared error (MSE):\n\\[\n\\mathrm{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} \\big(y_i - \\hat{f}(x_i)\\big)^2\n\\] But this MSE above is training MSE, which we don’t care about.\nWe are interested in the accuracy of the predictions that we obtain when we apply our method to previously unseen test data.\nThus, we could compute the average squared prediction error for these test observations \\((x_0, y_0)\\):\n\\[\n\\mathrm{Ave}\\big( (y_0 - \\hat{f}(x_0))^2 \\big)\n\\]\nwhere \\((x_0, y_0)\\) is a previously unseen test observation not used to train the statistical learning method.\nAs model flexibility increases, the training MSE will decrease, but the test MSE may not. When a given method yields a small training MSE but a large test MSE, we are said to be overfitting the data.\nOne important method is cross-validation (Chapter 5), which is a method for estimating the test MSE using the training data.\n\n\n2.2.2 The Bias-Variance Trade-Off\nFor a given value \\(x_0\\), the expected test MSE can always be decomposed into the sum of three fundamental quantities: the variance of \\(\\hat{f}(x_0)\\), the squared bias of \\(\\hat{f}(x_0)\\), and the variance of the error terms \\(\\epsilon\\)\nThat is (bias–variance trade-off)\n\\[\nE\\big( y_0 - \\hat{f}(x_0) \\big)^2\n= \\mathrm{Var}\\big(\\hat{f}(x_0)\\big)\n+ \\big[ \\mathrm{Bias}\\big(\\hat{f}(x_0)\\big) \\big]^2\n+ \\mathrm{Var}(\\epsilon)\n\\]\nThis equation tells us that in order to minimize the expected test error, we need to select a statistical learning method that simultaneously achieves low variance and low bias.\nvariance — the amount by which \\(\\hat{f}\\) would change if we estimated it using a different training data set\nIn general, more flexible statistical methods have higher variance.\nbias — the error that is introduced by approximating a real-life problem, which may be extremely complicated, by a much simpler model\nIn general, more flexible methods result in less bias.\n\n\n2.2.3 The Classification Setting\ntraining error rate (the fraction of incorrect classifications)\n\\[\n\\frac{1}{n} \\sum_{i=1}^{n} I(y_i \\neq \\hat{y}_i)\n\\] Here, \\(\\hat{y}_i\\) is the predicted class label for the \\(i\\)th observation using \\(\\hat{f}\\). And \\(I(y_i \\neq \\hat{y}_i)\\) is an indicator variable that equals 1 if \\(y_i \\neq \\hat{y}_i\\) and 0 if \\(y_i = \\hat{y}_i\\). If \\(I(y_i \\neq \\hat{y}_i) = 0\\), then the \\(i\\)th observation was classified correctly by our classification method; otherwise it was misclassified.\ntest error rate\n\\[\n\\mathrm{Ave}\\big(I(y_0 \\neq \\hat{y}_0)\\big)\n\\]"
  },
  {
    "objectID": "notes/ML.html#chapter-5",
    "href": "notes/ML.html#chapter-5",
    "title": "Machine Learning",
    "section": "Chapter 5",
    "text": "Chapter 5\nResampling methods: cross-validation, bootstrap\ncross-validation can be used to estimate the test error associated with a given statistical learning method in order to evaluate its performance, or to select the appropriate level of flexibility.\nThe bootstrap is used in several contexts, most commonly to provide a measure of accuracy of a parameter estimate or of a given statistical learning method.\nmodel assessment — the process of evaluating a model’s performance\nmodel selection — the process of selecting the proper level of flexibility for a model\n\nThe Validation Set Approach\nSplitting the set of observations into the training set and the validation set.\nTwo drawback\n\nthe validation estimate of the test error rate can be highly variable, depending on precisely which observations are included in the training set and which observations are included in the validation set.\nthe validation set error rate may tend to overestimate the test error rate for the model fit on the entire data set (only a subset of the observations, the training set, are used to fit the model—since statistical methods tend to perform worse when trained on fewer observations).\n\ncross-validation — a refinement of the validation set approach\n\n\nLeave-One-Out Cross-Validation\n\nvalidation set — \\((x_1, y_1)\\)\ntraining set — \\(\\{(x_2, y_2), \\dots, (x_n, y_n)\\}\\)\nThe statistical learning method is fit on the n − 1 training observations, repeat n times with a different validation observation.\n\nIn other words,\nIn the \\(i\\)-th iteration of LOOCV, the training set contains all observations except the \\(i\\)-th one:\n\\[\n\\mathrm{Training set}_i = (x_1, y_1), \\dots, (x_{i-1}, y_{i-1}), (x_{i+1}, y_{i+1}), \\dots, (x_n, y_n)\n\\]\nThe validation set consists of the single observation \\((x_i, y_i)\\). This procedure is repeated for \\(i = 1, \\dots, n\\).\nRepeating this approach \\(n\\) times produces \\(n\\) squared errors, \\(\\mathrm{MSE}_1, \\dots, \\mathrm{MSE}_n\\). The LOOCV estimate for the test \\(\\mathrm{MSE}\\) is the average of these \\(n\\) test error estimates:\n\\[\n\\mathrm{CV}(n) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathrm{MSE}_i\n\\] With least squares linear or polynomial regression:\n\\[\n\\mathrm{CV}(n) = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{y_i - \\hat{y}_i}{1 - h_i} \\right)^2\n\\] where \\(\\hat{y}_i\\) is the \\(i\\)th fitted value from the original least squares fit, and \\(h_i\\) is the leverage defined in (3.37) on page 99.\n\n\nk-Fold Cross-Validation\nk-fold CV involves randomly dividing the set of observations into k groups, or folds, of approximately equal size.\nThe \\(k\\)-fold CV estimate is computed by averaging these values:\n\\[\n\\mathrm{CV}(k) = \\frac{1}{k} \\sum_{i=1}^{k} \\mathrm{MSE}_i.\n\\]\nLOOCV is a special case of k-fold CV in which k is set to equal n.\nIn practice, one typically performs k-fold CV using k = 5 or k = 10.\nThe goal here is to identify the method that results in the lowest test error; for this purpose, the location of the minimum point on the estimated test \\(\\mathrm{MSE}\\) curve is important, while the actual value of the estimated \\(\\mathrm{MSE}\\) is not important.\n\n\nBias-Variance Trade-Off for k-Fold Cross-Validation\nLOOCV — low bias (approximately unbiased estimates) but high variance!\nSince the mean of many highly correlated quantities has higher variance than does the mean of many quantities that are not as highly correlated, the test error estimate resulting from LOOCV tends to have higher variance than does the test error estimate resulting from k-fold CV.\n\n\nCross-Validation on Classification Problems\nIn the classification setting, the LOOCV error rate takes the form\n\\[\n\\mathrm{CV}_{(n)} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathrm{Err}_i\n\\] where \\(\\mathrm{Err}_i = I(y_i \\neq \\hat{y}_i)\\)"
  },
  {
    "objectID": "notes/ML.html#chapter-6",
    "href": "notes/ML.html#chapter-6",
    "title": "Machine Learning",
    "section": "Chapter 6",
    "text": "Chapter 6"
  },
  {
    "objectID": "notes/ML.html#chapter-7",
    "href": "notes/ML.html#chapter-7",
    "title": "Machine Learning",
    "section": "Chapter 7",
    "text": "Chapter 7"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yukun Jiao",
    "section": "",
    "text": "Yukun Jiao is a Master’s student in Computational Social Science at Linköping University.\nWhen not being a nerd over computational social science, he enjoys pretending to work out and watching ducks, pigeons, and seagulls. Yukun was born and raised in North China."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Yukun Jiao",
    "section": "",
    "text": "Yukun Jiao is a Master’s student in Computational Social Science at Linköping University.\nWhen not being a nerd over computational social science, he enjoys pretending to work out and watching ducks, pigeons, and seagulls. Yukun was born and raised in North China."
  },
  {
    "objectID": "index.html#research-interests",
    "href": "index.html#research-interests",
    "title": "Yukun Jiao",
    "section": "Research Interests",
    "text": "Research Interests\n\nCausal Inference\nSocial Network Analysis\nComputational Text Analysis"
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Yukun Jiao",
    "section": "Projects",
    "text": "Projects\n\nResearch Internship in THE COMPLETE NETWORK OF SWEDEN"
  },
  {
    "objectID": "index.html#publications",
    "href": "index.html#publications",
    "title": "Yukun Jiao",
    "section": "Publications",
    "text": "Publications\n\nNone yet ¯\\_(ツ)_/¯"
  },
  {
    "objectID": "index.html#activities",
    "href": "index.html#activities",
    "title": "Yukun Jiao",
    "section": "Activities",
    "text": "Activities\n\nVolunteered at SICSS-IAS 2025\nSneaked into Sunbelt 2025 — unregistered but had fun\nVolunteered at IC2S2 2025"
  },
  {
    "objectID": "index.html#contact-me",
    "href": "index.html#contact-me",
    "title": "Yukun Jiao",
    "section": "Contact me",
    "text": "Contact me\n\nEmail: yukji739@student.liu.se \nInstagram: yukunjiao233"
  },
  {
    "objectID": "notes/index.html",
    "href": "notes/index.html",
    "title": "My Notes",
    "section": "",
    "text": "Click the links below to view the detailed notes:\n\nMachine Learning"
  }
]