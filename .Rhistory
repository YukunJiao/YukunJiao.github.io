comparison_df <- data.frame(train_predictions=mymodel$fitted.values,
observed=mymodel$y)
# Apply prediction threshold
comparison_df$train_predictions<-ifelse(comparison_df$train_predictions>=0.5,
yes = 1,
no = 0)
# Compute accuracy (scale: 0-1, 0=0%, 1=100%)
nrow(comparison_df[comparison_df$train_predictions==comparison_df$observed,]) /
nrow(comparison_df)
trumpbernie$trump_tweet <- factor(trumpbernie$trump_tweet, levels = c(0,1))
View(trumpbernie)
trumpbernie$trump_tweet
# format the outcome variable as a factor variable
trumpbernie$trump_tweet <- factor(trumpbernie$trump_tweet, levels = c(0,1))
# Use package "caret" to do k-fold cross-validation
tc <- caret::trainControl(method = 'cv', number = 3)
set.seed(12345) # Set to ensure that folds are the same across models
linear_model <- caret::train(trump_tweet ~ .,
data = trumpbernie,
method = "glm",
trControl = tc,
family = "binomial")
linear_model$results
?caret::train
linear_model <- caret::train(trump_tweet ~ .,
data = trumpbernie,
method = "glm",
trControl = tc,
family = binomial())
linear_model$results
pred_class <- predict(linear_model, newdata = trumpbernie)
pred_class <- predict(linear_model, newdata = trumpbernie)
train_acc <- mean(pred_class == trumpbernie$trump_tweet)
train_acc <- mean(pred_class == trumpbernie$trump_tweet)
train_acc
linear_model$results
pred_class <- predict(linear_model, newdata = trumpbernie)
linear_model$results
coef(mymodel)[(1010:1050)]
mymodel <- glm(trump_tweet ~ ., data = trumpbernie, family="binomial")
coef(mymodel)[(1010:1050)]
coef(mymodel)[(500:1050)]
coef(mymodel)[(900:1050)]
coef(mymodel)[(950:1050)]
coef(mymodel)[(999:1050)]
coef(mymodel)[(1:1050)]
coef(mymodel)[(1004:1050)]
coef(mymodel)[(1004:1100)]
View(trumpbernie)
coef(mymodel)[(1004:1100)]
coef(mymodel)[(1007:1100)]
coef(mymodel)[(1006:1100)]
coef(mymodel)[(1007:1100)]
coef(mymodel)[(1007:1200)]
coef(mymodel)[(1:10)]
coef(mymodel)[(1:20)]
coef(mymodel)[(0:20)]
coef(mymodel)[(1:20)]
test <-
coef(mymodel)[(1007:1200)]
test <- coef(mymodel)
test
test <- coef(mymodel) |> data.frame()
View(test)
sum(is.na(test))
sum(!is.na(test))
mymodel <- glm(trump_tweet ~ ., data = trumpbernie, family="binomial", na.action = na.exclude)
test <- coef(mymodel) |> data.frame()
sum(!is.na(test))
mymodel <- glm(trump_tweet ~ ., data = trumpbernie, family="binomial")
test <- coef(mymodel) |> data.frame()
test <- coef(mymodel) |> data.frame()
sum(!is.na(test))
View(test)
View(trumpbernie)
is.na(trumpbernie)
sum(is.na(trumpbernie))
x <- trumpbernie[, setdiff(names(trumpbernie), "trump_tweet")]
combos <- findLinearCombos(x)
combos
combos <- findLinearCombos(x)
mymodel <- glm(trump_tweet ~ ., data = trumpbernie, family="binomial")
trumpbernie$trump_tweet <- factor(trumpbernie$trump_tweet, levels = c(0,1))
mymodel <- glm(trump_tweet ~ ., data = trumpbernie, family="binomial")
test <- coef(mymodel) |> data.frame()
test <- coef(mymodel) |> data.frame()
sum(!is.na(test))
cor_matrix <- cor(trumpbernie, use = "pairwise.complete.obs")
alias(mymodel)
library(data.table)
library(glmnet)
library(ggplot2)
library(mlbench)
library(caret)
library(splines)
library(ggeffects)
# load data
trumpbernie <- fread(file = "~/Documents/ML/Labs/Lab1/trumpbernie.csv")
# inspect
trumpbernie[1:10,1:10]
dim(trumpbernie)
mymodel <- glm(trump_tweet ~ ., data = trumpbernie, family="binomial")
# test <- coef(mymodel) |> data.frame()
# sum(!is.na(test))
coef(mymodel)[(1001:1050)]
# Extract predictions on training data & observed values
comparison_df <- data.frame(train_predictions=mymodel$fitted.values,
observed=mymodel$y)
# Apply prediction threshold
comparison_df$train_predictions<-ifelse(comparison_df$train_predictions>=0.5,
yes = 1,
no = 0)
# Compute accuracy (scale: 0-1, 0=0%, 1=100%)
nrow(comparison_df[comparison_df$train_predictions==comparison_df$observed,]) /
nrow(comparison_df)
# test <- coef(mymodel) |> data.frame()
# sum(!is.na(test))
coef(mymodel)[(1001:1050)]
# load data
trumpbernie <- fread(file = "~/Documents/ML/Labs/Lab1/trumpbernie.csv")
# inspect
trumpbernie[1:10,1:10]
dim(trumpbernie)
# test <- coef(mymodel) |> data.frame()
# sum(!is.na(test))
coef(mymodel)[(1001:1050)]
# Extract predictions on training data & observed values
comparison_df <- data.frame(train_predictions=mymodel$fitted.values,
observed=mymodel$y)
# Apply prediction threshold
comparison_df$train_predictions<-ifelse(comparison_df$train_predictions>=0.5,
yes = 1,
no = 0)
# Compute accuracy (scale: 0-1, 0=0%, 1=100%)
nrow(comparison_df[comparison_df$train_predictions==comparison_df$observed,]) /
nrow(comparison_df)
# format the outcome variable as a factor variable
trumpbernie$trump_tweet <- factor(trumpbernie$trump_tweet, levels = c(0,1))
# Use package "caret" to do k-fold cross-validation
tc <- caret::trainControl(method = 'cv', number = 3)
set.seed(12345) # Set to ensure that folds are the same across models
linear_model <- caret::train(trump_tweet ~ .,
data = trumpbernie,
method = "glm",
trControl = tc,
family = "binomial")
linear_model$results
pred_class <- predict(linear_model, newdata = trumpbernie)
train_acc <- mean(pred_class == trumpbernie$trump_tweet)
train_acc
linear_model$results
pred_class <- predict(linear_model, newdata = trumpbernie)
train_acc <- mean(pred_class == trumpbernie$trump_tweet)
train_acc
train_acc
train_acc <- mean(pred_class == trumpbernie$trump_tweet)
train_acc
View(trumpbernie)
X <- trumpbernie[,-c('trump_tweet'),with=F] # Exclude response and id columns.
X <- as.matrix(X) # Make input data into a matrix
View(X)
cvglmnet_extra <- cv.glmnet(x = X,
y = trumpbernie$trump_tweet,
nfolds = 5,
standardize = TRUE,
family='binomial',
alpha=0,
type.measure = 'class')
cvglmnet <- cv.glmnet(x = X,
y = trumpbernie$trump_tweet,
nfolds = 5,
standardize = TRUE,
family='binomial',
alpha=0,
type.measure = 'class')
X <- trumpbernie[,-c('trump_tweet'),with=F] # Exclude response and id columns.
X <- as.matrix(X) # Make input data into a matrix
cvglmnet <- cv.glmnet(x = X,
y = trumpbernie$trump_tweet,
nfolds = 5,
standardize = TRUE,
family='binomial',
alpha=0,
type.measure = 'class')
cvglmnet
plot(cvglmnet, sign.lambda = 1)
plot(cvglmnet, sign.lambda = 0)
plot(cvglmnet, sign.lambda = 1)
X <- trumpbernie[,-c('trump_tweet'),with=F] # Exclude response and id columns.
X <- as.matrix(X) # Make input data into a matrix
cvglmnet <- cv.glmnet(x = X,
y = trumpbernie$trump_tweet,
nfolds = 5,
standardize = TRUE,
family='binomial',
alpha=0,
type.measure = 'class')
cvglmnet
plot(cvglmnet, sign.lambda = 1)
coef(myfit, s='lambda.min')
coef(cvglmnet, s='lambda.min')
best_coefs <- coef(cvglmnet, s = "lambda.min")
best_coefs <- coef(cvglmnet, s = "lambda.min")
best_coefs
best_coefs_dt <- data.table(word=rownames(best_coefs),
coef=best_coefs[,1])
best_coefs_dt
best_coefs_dt[order(coef,decreasing = T)]
best_coefs <- coef(cvglmnet, s = "lambda.min")
best_coefs_dt <- data.table(word=rownames(best_coefs),
coef=best_coefs[,1])
best_coefs_dt[order(coef,decreasing = T)]
View(best_coefs_dt)
View(best_coefs_dt)
sna_data <- fread("~/Documents/ML/Labs/Lab1/Kaggle_Social_Network_Ads.csv")
sna_data <- fread("~/Documents/ML/Labs/Lab1/Kaggle_Social_Network_Ads.csv")
View(sna_data)
sna_data$Purchased <- factor(sna_data$Purchased, levels = c(0,1))
X <- sna_data[,-c('Purchased'),with=F] # Exclude response and id columns.
X <- as.matrix(X) # Make input data into a matrix
X <- sna_data[,-c('Purchased'),with=F] # Exclude response and id columns.
X <- as.matrix(X) # Make input data into a matrix
cvglmnet <- cv.glmnet(x = X,
y = sna_data$Purchased,
nfolds = 5,
standardize = TRUE,
family='binomial',
alpha=0,
type.measure = 'class')
# Use package "caret" to do k-fold cross-validation
tc <- caret::trainControl(method = 'cv', number = 5)
set.seed(12345) # Set to ensure that folds are the same across models
# Use package "caret" to do k-fold cross-validation
tc <- caret::trainControl(method = 'cv', number = 5)
set.seed(12345) # Set to ensure that folds are the same across models
linear_model <- caret::train(Purchased ~ .,
data = sna_data,
method = "glm",
trControl = tc,
family = "binomial")
# Use package "caret" to do k-fold cross-validation
tc <- caret::trainControl(method = 'cv', number = 5)
set.seed(12345) # Set to ensure that folds are the same across models
linear_model <- caret::train(Purchased ~ .,
data = sna_data,
method = "glm",
trControl = tc,
family = "binomial")
# Use package "caret" to do k-fold cross-validation
tc <- caret::trainControl(method = 'cv', number = 5)
set.seed(12345) # Set to ensure that folds are the same across models
linear_model <- caret::train(Purchased ~ .,
data = sna_data,
method = "glm",
trControl = tc,
family = "binomial")
linear_model
linear_model$results
pred_class <- predict(linear_model, newdata = sna_data)
train_acc <- mean(pred_class == sna_data$Purchased)
train_acc
linear_model$results
train_acc
library(data.table)
library(glmnet)
library(ggplot2)
library(mlbench)
library(caret)
library(splines)
library(ggeffects)
# load data
trumpbernie <- fread(file = "~/Documents/ML/Labs/Lab1/trumpbernie.csv")
# inspect
trumpbernie[1:10,1:10]
dim(trumpbernie)
# format the outcome variable as a factor variable
trumpbernie$trump_tweet <- factor(trumpbernie$trump_tweet, levels = c(0,1))
# Use package "caret" to do k-fold cross-validation
tc <- caret::trainControl(method = 'cv', number = 3)
set.seed(12345) # Set to ensure that folds are the same across models
linear_model <- caret::train(trump_tweet ~ .,
data = trumpbernie,
method = "glm",
trControl = tc,
family = "binomial")
linear_model$results
linear_model$results
pred_class <- predict(linear_model, newdata = trumpbernie)
pred_class <- predict(linear_model, newdata = trumpbernie)
train_acc <- mean(pred_class == trumpbernie$trump_tweet)
train_acc <- mean(pred_class == trumpbernie$trump_tweet)
train_acc
sna_data <- fread("~/Documents/ML/Labs/Lab1/Kaggle_Social_Network_Ads.csv")
sna_data$Purchased <- factor(sna_data$Purchased, levels = c(0,1))
# Use package "caret" to do k-fold cross-validation
tc <- caret::trainControl(method = 'cv', number = 5)
set.seed(12345) # Set to ensure that folds are the same across models
linear_model <- caret::train(Purchased ~ .,
data = sna_data,
method = "glm",
trControl = tc,
family = "binomial")
linear_model
linear_model$results
pred_class <- predict(linear_model, newdata = sna_data)
train_acc <- mean(pred_class == sna_data$Purchased)
train_acc
linear_model
linear_model$results
pred_class <- predict(linear_model, newdata = sna_data)
train_acc <- mean(pred_class == sna_data$Purchased)
train_acc
linear_model$results
X <- trumpbernie[,-c('trump_tweet'),with=F] # Exclude response and id columns.
X <- as.matrix(X) # Make input data into a matrix
X
sna_data_dt <- as.data.table(sna_data)
View(sna_data_dt)
View(sna_data)
View(sna_data_dt)
View(sna_data)
set.seed(12345) # Set to ensure that folds are the same across models
gam_model1 <- caret::train(Purchased ~ ns(Age,2) + ns(Salary, 2) + Gender,
data = sna_data,
method = "lm",
trControl = tc)
gam_model2 <- caret::train(Purchased ~ ns(Age,3) + ns(Salary, 3) + Gender,
data = sna_data,
method = "lm",
trControl = tc)
gam_model3 <- caret::train(Purchased ~ ns(Age,4) + ns(Salary, 4) + Gender,
data = sna_data,
method = "lm",
trControl = tc)
set.seed(12345) # Set to ensure that folds are the same across models
gam_model1 <- caret::train(Purchased ~ ns(Age,2) + ns(Salary, 2) + Gender,
data = sna_data,
method = "glm",
trControl = tc,
family = "binomial")
gam_model2 <- caret::train(Purchased ~ ns(Age,3) + ns(Salary, 3) + Gender,
data = sna_data,
method = "lm",
trControl = tc,
family = "binomial")
gam_model3 <- caret::train(Purchased ~ ns(Age,4) + ns(Salary, 4) + Gender,
data = sna_data,
method = "lm",
trControl = tc,
family = "binomial")
gam_model1 <- caret::train(Purchased ~ ns(Age,2) + ns(Salary, 2) + Gender,
data = sna_data,
method = "glm",
trControl = tc,
family = "binomial")
gam_model2 <- caret::train(Purchased ~ ns(Age,3) + ns(Salary, 3) + Gender,
data = sna_data,
method = "glm",
trControl = tc,
family = "binomial")
gam_model3 <- caret::train(Purchased ~ ns(Age,4) + ns(Salary, 4) + Gender,
data = sna_data,
method = "glm",
trControl = tc,
family = "binomial")
set.seed(12345) # Set to ensure that folds are the same across models
gam_model1 <- caret::train(Purchased ~ ns(Age,2) + ns(Salary, 2),
data = sna_data,
method = "glm",
trControl = tc,
family = "binomial")
gam_model2 <- caret::train(Purchased ~ ns(Age,3) + ns(Salary, 3),
data = sna_data,
method = "glm",
trControl = tc,
family = "binomial")
gam_model3 <- caret::train(Purchased ~ ns(Age,4) + ns(Salary, 4),
data = sna_data,
method = "glm",
trControl = tc,
family = "binomial")
gam_model1$results
gam_model2$results
gam_model3$results
gam_model1$results
gam_model2$results
gam_model3$results
gam_model1$results
```{r}
X <- trumpbernie[,-c('trump_tweet'),with=F] # Exclude response and id columns.
X <- as.matrix(X) # Make input data into a matrix
X
trumpbernie[,-c('trump_tweet'),with=F]
trumpbernie[,-c('trump_tweet')]
trumpbernie[,-c('trump_tweet'),with=F]
test1 <- trumpbernie[,-c('trump_tweet'),with=F]
test2 <- trumpbernie[,-c('trump_tweet')]
test3 <- trumpbernie[,'trump_tweet']
test1 <- trumpbernie[,-c('trump_tweet'),with=F]
test2 <- trumpbernie[,-c('trump_tweet')]
test3 <- trumpbernie[,'trump_tweet']
test1 <- trumpbernie[,-c('trump_tweet'),with=F]
test2 <- trumpbernie[,-c('trump_tweet')]
test3 <- trumpbernie[,-'trump_tweet']
X <- as.matrix(test3) # Make input data into a matrix
cvglmnet <- cv.glmnet(x = X,
y = trumpbernie$trump_tweet,
nfolds = 5,
standardize = TRUE,
family='binomial',
alpha=0,
type.measure = 'class')
cvglmnet <- cv.glmnet(x = X,
y = trumpbernie$trump_tweet,
nfolds = 5,
standardize = TRUE,
family='binomial',
alpha=0,
type.measure = 'class')
cvglmnet
test3 <- trumpbernie[,-trump_tweet]
test4 <- trumpbernie[,-trump_tweet]
test1 <- trumpbernie[,-c('trump_tweet'),with=F]
test2 <- trumpbernie[,-c('trump_tweet')]
test3 <- trumpbernie[,-'trump_tweet']
test4 <- trumpbernie[,-trump_tweet]
X <- trumpbernie[,-c('trump_tweet'),with=F] # Exclude response and id columns.
X <- as.matrix(X) # Make input data into a matrix
cvglmnet <- cv.glmnet(x = X,
y = trumpbernie$trump_tweet,
nfolds = 5,
standardize = TRUE,
family='binomial',
alpha=0,
type.measure = 'class')
cvglmnet <- cv.glmnet(x = X,
y = trumpbernie$trump_tweet,
nfolds = 5,
standardize = TRUE,
family='binomial',
alpha=0,
type.measure = 'class')
cvglmnet
final_model <- lm(Purchased ~ ns(Age,2) + ns(Salary, 2), data=sna_data)
final_model <- lm(Purchased ~ ns(Age,2) + ns(Salary, 2), data=sna_data, family = "binomial")
final_model <- glm(Purchased ~ ns(Age,2) + ns(Salary, 2), data=sna_data, family = "binomial")
ggpredict
final_model <- glm(Purchased ~ ns(Age,2) + ns(Salary, 2), data=sna_data, family = "binomial")
{
ggpreds <- ggpredict(final_model)
plot(ggpreds)
}
cvglmnet <- cv.glmnet(x = X,
y = trumpbernie$trump_tweet,
nfolds = 5,
standardize = TRUE,
family='binomial',
alpha=0,
type.measure = 'class')
cvglmnet <- cv.glmnet(x = X,
y = trumpbernie$trump_tweet,
nfolds = 5,
standardize = TRUE,
family='binomial',
alpha=0,
type.measure = 'class')
cvglmnet
plot(cvglmnet, sign.lambda = 1)
1-0.08375
library(data.table)
library(glmnet)
library(ggplot2)
library(mlbench)
library(caret)
library(splines)
library(ggeffects)
# load data
trumpbernie <- fread(file = "~/Documents/ML/Labs/Lab1/trumpbernie.csv")
# inspect
trumpbernie[1:10,1:10]
dim(trumpbernie)
mymodel <- glm(trump_tweet ~ ., data = trumpbernie, family="binomial")
```{r, cache=TRUE}
mymodel <- glm(trump_tweet ~ ., data = trumpbernie, family="binomial")
mymodel <- glm(trump_tweet ~ ., data = trumpbernie, family="binomial")
set.seed(12345)
mymodel <- glm(trump_tweet ~ ., data = trumpbernie, family="binomial")
set.seed(12345)
mymodel <- glm(trump_tweet ~ ., data = trumpbernie, family="binomial")
# test <- coef(mymodel) |> data.frame()
# sum(!is.na(test))
coef(mymodel)[(1001:1050)]
# Extract predictions on training data & observed values
comparison_df <- data.frame(train_predictions=mymodel$fitted.values,
observed=mymodel$y)
# Apply prediction threshold
comparison_df$train_predictions<-ifelse(comparison_df$train_predictions>=0.5,
yes = 1,
no = 0)
# Compute accuracy (scale: 0-1, 0=0%, 1=100%)
nrow(comparison_df[comparison_df$train_predictions==comparison_df$observed,]) /
nrow(comparison_df)
# format the outcome variable as a factor variable
trumpbernie$trump_tweet <- factor(trumpbernie$trump_tweet, levels = c(0,1))
# Use package "caret" to do k-fold cross-validation
tc <- caret::trainControl(method = 'cv', number = 3)
set.seed(12345) # Set to ensure that folds are the same across models
linear_model <- caret::train(trump_tweet ~ .,
data = trumpbernie,
method = "glm",
trControl = tc,
family = "binomial")
